{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4969c35",
   "metadata": {},
   "source": [
    "DDLs for empty tales in Gold Layer Notebook\n",
    "\n",
    "-you can version your schemas and evolve them as needed while maintaining backward compatibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ea443d-32fd-4beb-b736-44a613d10e7e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-12-18T10:52:32.3481454Z",
       "execution_start_time": "2024-12-18T10:52:17.561379Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "93ee7403-e857-444c-8602-233a208d417e",
       "queued_time": "2024-12-18T10:52:06.3723607Z",
       "session_id": "16e20c64-3521-4e87-8ff8-853f6726d2ae",
       "session_start_time": "2024-12-18T10:52:06.963891Z",
       "spark_pool": null,
       "state": "finished",
       "statement_id": 3,
       "statement_ids": [
        3
       ]
      },
      "text/plain": [
       "StatementMeta(, 16e20c64-3521-4e87-8ff8-853f6726d2ae, 3, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Create the schema\n",
    "spark.sql(f'CREATE SCHEMA IF NOT EXISTS adventureworks')\n",
    "\n",
    "# Define the schema for address\n",
    "schemaAddress = StructType([\n",
    "    StructField(\"ID\", StringType()),\n",
    "    StructField(\"AddressID\", IntegerType()),\n",
    "    StructField(\"AddressLine1\", StringType()),\n",
    "    StructField(\"AddressLine2\", StringType()),\n",
    "    StructField(\"City\", StringType()),\n",
    "    StructField(\"StateProvince\", StringType()),\n",
    "    StructField(\"CountryRegion\", StringType()),\n",
    "    StructField(\"current_flag\", BooleanType()),\n",
    "    StructField(\"current_date\", DateType()),\n",
    "    StructField(\"end_date\", DateType())\n",
    "])\n",
    "\n",
    "# Create the DataFrame\n",
    "dfAddress = spark.createDataFrame([], schemaAddress)\n",
    "\n",
    "# Create the table\n",
    "dfAddress.write.mode(\"append\").saveAsTable(\"adventureworks.dimension_address\")\n",
    "\n",
    "# Define the schema for customer\n",
    "schemaCustomer = StructType([\n",
    "    StructField(\"ID\", StringType()),\n",
    "    StructField(\"CustomerID\", IntegerType()),\n",
    "    StructField(\"Title\", StringType()),\n",
    "    StructField(\"FirstName\", StringType()),\n",
    "    StructField(\"MiddleName\", StringType()),\n",
    "    StructField(\"LastName\", StringType()),\n",
    "    StructField(\"CompanyName\", StringType()),\n",
    "    StructField(\"EmailAddress\", StringType()),\n",
    "    StructField(\"Phone\", StringType()),\n",
    "    StructField(\"current_flag\", BooleanType()),\n",
    "    StructField(\"current_date\", DateType()),\n",
    "    StructField(\"end_date\", DateType())\n",
    "])\n",
    "\n",
    "# Create the DataFrame\n",
    "dfCustomer = spark.createDataFrame([], schemaCustomer)\n",
    "\n",
    "# Create the table\n",
    "dfCustomer.write.mode(\"append\").saveAsTable(\"adventureworks.dimension_customer\")\n",
    "\n",
    "# Define the schema for date\n",
    "schemaDate = StructType([\n",
    "    StructField(\"ID\", StringType()),\n",
    "    StructField(\"OrderDate\", DateType()),\n",
    "    StructField(\"Day\", IntegerType()),\n",
    "    StructField(\"Month\", IntegerType()),\n",
    "    StructField(\"Year\", IntegerType())\n",
    "])\n",
    "\n",
    "# Create the DataFrame\n",
    "dfDate = spark.createDataFrame([], schemaDate)\n",
    "\n",
    "# Create the table\n",
    "dfDate.write.mode(\"append\").saveAsTable(\"adventureworks.dimension_date\")\n",
    "\n",
    "# Define the schema for product\n",
    "schemaProduct = StructType([\n",
    "    StructField(\"ID\", StringType()),\n",
    "    StructField(\"ProductID\", IntegerType()),\n",
    "    StructField(\"ProductNumber\", StringType()),\n",
    "    StructField(\"Color\", StringType()),\n",
    "    StructField(\"Size\", StringType()),\n",
    "    StructField(\"Weight\", StringType()),\n",
    "    StructField(\"CategoryName\", StringType()),\n",
    "    StructField(\"ProductModelName\", StringType()),\n",
    "    StructField(\"current_flag\", BooleanType()),\n",
    "    StructField(\"current_date\", DateType()),\n",
    "    StructField(\"end_date\", DateType())\n",
    "])\n",
    "\n",
    "# Create the DataFrame\n",
    "dfProduct = spark.createDataFrame([], schemaProduct)\n",
    "\n",
    "# Create the table\n",
    "dfProduct.write.mode(\"append\").saveAsTable(\"adventureworks.dimension_product\")\n",
    "\n",
    "# Define the schema for sales\n",
    "schemaSales = StructType([\n",
    "    StructField(\"SalesKey\", StringType()),\n",
    "    StructField(\"AddressKey\", StringType()),\n",
    "    StructField(\"CustomerKey\", StringType()),\n",
    "    StructField(\"ProductKey\", StringType()),\n",
    "    StructField(\"DateKey\", StringType()),\n",
    "    StructField(\"Revenue\", DoubleType()),\n",
    "    StructField(\"OrderQty\", IntegerType()),\n",
    "    StructField(\"UnitPrice\", DoubleType()),\n",
    "    StructField(\"current_flag\", BooleanType()),\n",
    "    StructField(\"current_date\", DateType()),\n",
    "    StructField(\"end_date\", DateType())\n",
    "])\n",
    "\n",
    "# Create the DataFrame\n",
    "dfSales = spark.createDataFrame([], schemaSales)\n",
    "\n",
    "# Create the table\n",
    "dfSales.write.mode(\"append\").saveAsTable(\"adventureworks.fact_sales\")"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "89b49d86-b090-4126-b03c-263e6f504321",
    "default_lakehouse_name": "Gold",
    "default_lakehouse_workspace_id": "30950d63-22f3-4d65-8813-310477df47b4",
    "known_lakehouses": [
     {
      "id": "89b49d86-b090-4126-b03c-263e6f504321"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "notebook_environment": {},
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "save_output": true,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    },
    "enableDebugMode": false
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
